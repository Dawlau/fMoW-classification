{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from erm_helpers import *\n",
    "from Classifier import Classifier\n",
    "from SubsampledDataset import SubsampledDataset, NUM_CLASSES\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "# device = \"cpu\"\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Load train and validation data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=10'>11</a>\u001b[0m ood_val_data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_subset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=11'>12</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=12'>13</a>\u001b[0m     transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=13'>14</a>\u001b[0m         [transforms\u001b[39m.\u001b[39mToTensor()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=14'>15</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=15'>16</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=17'>18</a>\u001b[0m id_val_data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_subset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mid_val\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=19'>20</a>\u001b[0m     transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=20'>21</a>\u001b[0m         [transforms\u001b[39m.\u001b[39mToTensor()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=21'>22</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=22'>23</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=24'>25</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m SubsampledDataset(train_data, grouper)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=25'>26</a>\u001b[0m ood_val_dataset \u001b[39m=\u001b[39m SubsampledDataset(ood_val_data, grouper)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dawlau/Desktop/fMoW-classification/train_ERM_and_Unet.ipynb#ch0000003?line=26'>27</a>\u001b[0m id_val_dataset \u001b[39m=\u001b[39m SubsampledDataset(id_val_data, grouper)\n",
      "File \u001b[0;32m~/Desktop/fMoW-classification/SubsampledDataset.py:32\u001b[0m, in \u001b[0;36mSubsampledDataset.__init__\u001b[0;34m(self, dataset, grouper)\u001b[0m\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper \u001b[39m=\u001b[39m grouper\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=30'>31</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n\u001b[0;32m---> <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=31'>32</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=32'>33</a>\u001b[0m \ti \u001b[39mfor\u001b[39;00m i, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset) \u001b[39mif\u001b[39;00m SubsampledDataset\u001b[39m.\u001b[39mfilter_sample(sample, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper)\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=33'>34</a>\u001b[0m ]\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/fMoW-classification/SubsampledDataset.py:32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper \u001b[39m=\u001b[39m grouper\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=30'>31</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n\u001b[0;32m---> <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=31'>32</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=32'>33</a>\u001b[0m \ti \u001b[39mfor\u001b[39;00m i, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset) \u001b[39mif\u001b[39;00m SubsampledDataset\u001b[39m.\u001b[39mfilter_sample(sample, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper)\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=33'>34</a>\u001b[0m ]\n\u001b[1;32m     <a href='file:///home/dawlau/Desktop/fMoW-classification/SubsampledDataset.py?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py:498\u001b[0m, in \u001b[0;36mWILDSSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=496'>497</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m--> <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=497'>498</a>\u001b[0m     x, y, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=498'>499</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=499'>500</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_transform_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py:32\u001b[0m, in \u001b[0;36mWILDSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=29'>30</a>\u001b[0m     \u001b[39m# Any transformations are handled by the WILDSSubset\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=30'>31</a>\u001b[0m     \u001b[39m# since different subsets (e.g., train vs test) might have different transforms\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_input(idx)\n\u001b[1;32m     <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=32'>33</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_array[idx]\n\u001b[1;32m     <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/wilds_dataset.py?line=33'>34</a>\u001b[0m     metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_array[idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py:185\u001b[0m, in \u001b[0;36mFMoWDataset.get_input\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=180'>181</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=181'>182</a>\u001b[0m \u001b[39mReturns x for a given idx.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=182'>183</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=183'>184</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_idxs[idx]\n\u001b[0;32m--> <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=184'>185</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrgb_img_\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/wilds/datasets/fmow_dataset.py?line=185'>186</a>\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py:889\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=846'>847</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m):\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=847'>848</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=848'>849</a>\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=849'>850</a>\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=885'>886</a>\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=886'>887</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=888'>889</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=890'>891</a>\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=891'>892</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/Image.py?line=892'>893</a>\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=246'>247</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=247'>248</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=248'>249</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=249'>250</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=251'>252</a>\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=252'>253</a>\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=253'>254</a>\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/dawlau/anaconda3/envs/fmow/lib/python3.9/site-packages/PIL/ImageFile.py?line=254'>255</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(dataset=\"fmow\", download=False)\n",
    "grouper = CombinatorialGrouper(dataset, [\"region\"])\n",
    "\n",
    "train_data = dataset.get_subset(\n",
    "\t\t\"train\",\n",
    "\t  transform=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "ood_val_data = dataset.get_subset(\n",
    "    \"val\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "id_val_data = dataset.get_subset(\n",
    "    \"id_val\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_dataset = SubsampledDataset(train_data, grouper)\n",
    "ood_val_dataset = SubsampledDataset(ood_val_data, grouper)\n",
    "id_val_dataset = SubsampledDataset(id_val_data, grouper)\n",
    "\n",
    "train_loader = get_train_loader(\"standard\", train_dataset, batch_size=BATCH_SIZE)\n",
    "ood_val_loader = get_train_loader(\"standard\", ood_val_dataset, batch_size=BATCH_SIZE)\n",
    "id_val_loader = get_train_loader(\"standard\", id_val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'subsampled_data/train_dataset.pth')\n",
    "torch.save(ood_val_dataset, 'subsampled_data/ood_val_dataset.pth')\n",
    "torch.save(id_val_dataset, 'subsampled_data/id_val_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset=\"fmow\", download=False)\n",
    "\n",
    "train_dataset = torch.load('subsampled_data/train_dataset.pth')\n",
    "ood_val_dataset = torch.load('subsampled_data/ood_val_dataset.pth')\n",
    "id_val_dataset = torch.load('subsampled_data/id_val_dataset.pth')\n",
    "\n",
    "train_loader = get_train_loader(\"standard\", train_dataset, batch_size=BATCH_SIZE)\n",
    "ood_val_loader   = get_train_loader(\"standard\", ood_val_dataset, batch_size=BATCH_SIZE)\n",
    "id_val_loader    = get_train_loader(\"standard\", id_val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Train and accumulate evaluation per epoch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(2*min(len(train_loader), len(ood_val_loader)))):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, unet_loader, unet_loss_fn, unet_optimizer):\n",
    "  model.train()\n",
    "\n",
    "  accumulated_y_true = torch.tensor([]).to(device)\n",
    "  accumulated_y_pred = torch.tensor([]).to(device)\n",
    "  accumulated_metadata = torch.tensor([]).to(device)\n",
    "  loss_value = 0\n",
    "\n",
    "  loader_iter = iter(data_loader)\n",
    "  unet_iter = iter(unet_loader)\n",
    "  for i in tqdm(range(2*min(len(data_loader), len(unet_loader)))):\n",
    "    if i % 2:\n",
    "      x, y, metadata = next(loader_iter)\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      metadata = metadata.to(device)\n",
    "\n",
    "      model.zero_grad()\n",
    "\n",
    "      y_pred = model(x)\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      y_pred = torch.argmax(y_pred, dim=-1)\n",
    "\n",
    "      accumulated_y_true = torch.concat(\n",
    "        [accumulated_y_true, torch.flatten(y)], dim=0\n",
    "      )\n",
    "      accumulated_y_pred = torch.concat(\n",
    "        [accumulated_y_pred, torch.flatten(y_pred)], dim=0\n",
    "      )\n",
    "      accumulated_metadata = torch.concat(\n",
    "        [accumulated_metadata, metadata], dim=0\n",
    "      )\n",
    "      loss_value += loss.item()\n",
    "    else:\n",
    "      x, _, _ = next(unet_iter) # ignore labels and metadata\n",
    "      x = x.to(device)\n",
    "      model.zero_grad()\n",
    "      # train unet\n",
    "      x_pred = model.unet(x)\n",
    "          \n",
    "      loss = unet_loss_fn(x_pred, x)\n",
    "\n",
    "      # Backward pass\n",
    "      loss.backward()\n",
    "      unet_optimizer.step()\n",
    "\n",
    "\n",
    "  accumulated_y_true = accumulated_y_true.cpu()\n",
    "  accumulated_y_pred = accumulated_y_pred.cpu()\n",
    "  accumulated_metadata = accumulated_metadata.cpu()\n",
    "  loss_value = loss_value / len(data_loader)\n",
    "\n",
    "  return accumulated_y_true, accumulated_y_pred, accumulated_metadata, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_train(model, device, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    for image_batch, _, _ in tqdm(dataloader): # ignore labels and metadata\n",
    "        image_batch = image_batch.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        out = model(image_batch)\n",
    "        \n",
    "        loss = loss_fn(out, image_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.0001\n",
    "MODEL_PATH = \"models\"\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "model = Classifier(NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "# summary = summary(model, (3, 224, 224))\n",
    "\n",
    "model_name = f\"ERM_{NUM_CLASSES}_{NUM_EPOCHS}_SGD_{LEARNING_RATE}_{MOMENTUM}_CrossEntropy_unet_3blocks_full_train.pth\"\n",
    "save_name = os.path.join(MODEL_PATH, model_name)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "unet_loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "unet_optimizer = torch.optim.Adam(model.unet.parameters(), lr=LEARNING_RATE/2)\n",
    "\n",
    "train_evolution = []\n",
    "val_evolution = []\n",
    "id_val_evolution = []\n",
    "best_loss = sys.float_info.max\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  print(f\"EPOCH {epoch + 1}:\")\n",
    "  # train\n",
    "  y_true, y_pred, metadata, loss = train_epoch(model, train_loader, loss_fn, optimizer, device, ood_val_loader, unet_loss_fn, unet_optimizer)\n",
    "  train_evolution.append(build_metrics_dict(dataset, y_true, y_pred, metadata, loss))\n",
    "  print(f\"Train Loss: {loss}\")\n",
    "\n",
    "  # validation\n",
    "  y_true, y_pred, metadata, loss = val_step(model, ood_val_loader, loss_fn, device)\n",
    "  val_evolution.append(build_metrics_dict(dataset, y_true, y_pred, metadata, loss))\n",
    "  print(f\"OOD Loss: {loss}\")\n",
    "\n",
    "  # # save by best ood loss\n",
    "  if loss < best_loss:\n",
    "    best_loss = loss\n",
    "    torch.save(model, save_name)\n",
    "\n",
    "  # in distribution validation\n",
    "  y_true, y_pred, metadata, loss = val_step(model, id_val_loader, loss_fn, device)\n",
    "  id_val_evolution.append(build_metrics_dict(dataset, y_true, y_pred, metadata, loss))\n",
    "  print(f\"ID Loss: {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Plot loss and accuracy per region</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(train_evolution[0].keys())\n",
    "\n",
    "for metric in metrics:\n",
    "\tplot_graph(metric, train_evolution, val_evolution, id_val_evolution, len(train_evolution))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff1607acb86e9c06c30b27f75fb57134555e2c7e307c575a25fc991546615253"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fmow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
